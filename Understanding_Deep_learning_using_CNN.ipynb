{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep learning using CNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "J-0gnKVVhoj6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## UNDERSTANDING DEEP LEARNING USING CNN"
      ]
    },
    {
      "metadata": {
        "id": "YPVO1SY1jB0Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ABSTRACT\n",
        "\n",
        "**Context:**\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
        "\n",
        "Zalando seeks to replace the original MNIST dataset\n",
        "\n",
        "**Content:**\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n",
        "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below. \n",
        "\n",
        "**Labels:**\n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "0 T-shirt/top\n",
        "1 Trouser\n",
        "2 Pullover\n",
        "3 Dress\n",
        "4 Coat\n",
        "5 Sandal\n",
        "6 Shirt\n",
        "7 Sneaker\n",
        "8 Bag\n",
        "9 Ankle boot \n",
        "\n",
        "**Overview:**\n",
        "\n",
        "Each row is a separate image\n",
        "Column 1 is the class label.\n",
        "Remaining columns are pixel numbers (784 total).\n",
        "Each value is the darkness of the pixel (1 to 255)\n",
        "\n",
        "Kaggle link to dataset - https://www.kaggle.com/zalando-research/fashionmnist"
      ]
    },
    {
      "metadata": {
        "id": "I329wIUjhqb2",
        "colab_type": "code",
        "outputId": "d6f0308f-c090-49cb-ed75-a5ca3093037a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly import tools\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/vnd.plotly.v1+html": "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>",
            "text/html": [
              "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cwH85PT0a6em",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Metadata\n",
        "IMG_ROWS = 28\n",
        "IMG_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 0\n",
        "\n",
        "NO_EPOCHS = 2\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SU6tgz8QbM8g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Reading data from file\n",
        "train_data = pd.read_csv('fashion-mnist_train.csv')\n",
        "test_data = pd.read_csv('fashion-mnist_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HeEJjYaPbhxa",
        "colab_type": "code",
        "outputId": "03014567-0259-45f1-b005-6394db621843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Fashion MNIST train -  rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])\n",
        "print(\"Fashion MNIST test -  rows:\",test_data.shape[0],\" columns:\", test_data.shape[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fashion MNIST train -  rows: 60000  columns: 785\n",
            "Fashion MNIST test -  rows: 10000  columns: 785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8EO109pnb86a",
        "colab_type": "code",
        "outputId": "d344493d-d467-4d5d-dbab-acdb72f96583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
        "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
        "\n",
        "def get_classes_distribution(data):\n",
        "    # Get the count for each label\n",
        "    label_counts = data[\"label\"].value_counts()\n",
        "\n",
        "    # Get total number of samples\n",
        "    total_samples = len(data)\n",
        "\n",
        "\n",
        "    # Count the number of items in each class\n",
        "    for i in range(len(label_counts)):\n",
        "        label = labels[label_counts.index[i]]\n",
        "        count = label_counts.values[i]\n",
        "        percent = (count / total_samples) * 100\n",
        "        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))\n",
        "\n",
        "get_classes_distribution(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ankle Boot          :   6000 or 10.0%\n",
            "Bag                 :   6000 or 10.0%\n",
            "Sneaker             :   6000 or 10.0%\n",
            "Shirt               :   6000 or 10.0%\n",
            "Sandal              :   6000 or 10.0%\n",
            "Coat                :   6000 or 10.0%\n",
            "Dress               :   6000 or 10.0%\n",
            "Pullover            :   6000 or 10.0%\n",
            "Trouser             :   6000 or 10.0%\n",
            "T-shirt/top         :   6000 or 10.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GvF4GAm6cCDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_preprocessing(raw):\n",
        "    out_y = keras.utils.to_categorical(raw.label, NUM_CLASSES)\n",
        "    num_images = raw.shape[0]\n",
        "    x_as_array = raw.values[:,1:]\n",
        "    x_shaped_array = x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n",
        "    out_x = x_shaped_array / 255\n",
        "    return out_x, out_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkuZkmyicJpC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, y = data_preprocessing(train_data)\n",
        "X_test, y_test = data_preprocessing(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fP7nKa_5cMCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9YuQTzYcOQg",
        "colab_type": "code",
        "outputId": "8f67ae0f-5fa4-45fb-9344-08181a3137bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Fashion MNIST train -  rows:\",X_train.shape[0],\" columns:\", X_train.shape[1:4])\n",
        "print(\"Fashion MNIST valid -  rows:\",X_val.shape[0],\" columns:\", X_val.shape[1:4])\n",
        "print(\"Fashion MNIST test -  rows:\",X_test.shape[0],\" columns:\", X_test.shape[1:4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fashion MNIST train -  rows: 48000  columns: (28, 28, 1)\n",
            "Fashion MNIST valid -  rows: 12000  columns: (28, 28, 1)\n",
            "Fashion MNIST test -  rows: 10000  columns: (28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MMtGt2QfcRGw",
        "colab_type": "code",
        "outputId": "c4fcda61-6c47-4822-f4e6-f5e4a67b6e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "#Creating an object of Sequential class\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qbhnDY3lc6Tq",
        "colab_type": "code",
        "outputId": "afdd8a8a-fd54-4179-ca4e-16b75e5ba2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 241,546\n",
            "Trainable params: 241,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "akplP2Umc_Ty",
        "colab_type": "code",
        "outputId": "c29f3289-f2d8-48e8-cfcf-8fd8b9f1ea86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "#Fitting the model\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/2\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: 0.5330 - acc: 0.8052 - val_loss: 0.4270 - val_acc: 0.8445\n",
            "Epoch 2/2\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: 0.3450 - acc: 0.8741 - val_loss: 0.3472 - val_acc: 0.8735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ArPfUTTdDz-",
        "colab_type": "code",
        "outputId": "de5bdf31-e8c3-4917-dcb1-20cddddce924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.337430632686615\n",
            "Test accuracy: 0.8795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5-x0XewOh3QU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing activation function to sigmoid"
      ]
    },
    {
      "metadata": {
        "id": "va6KnxZxfIHo",
        "colab_type": "code",
        "outputId": "0c97f793-2171-49e5-a918-6607f51fc15e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='sigmoid',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='sigmoid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='sigmoid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/2\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 1.2211 - acc: 0.5518 - val_loss: 0.7218 - val_acc: 0.7237\n",
            "Epoch 2/2\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.6381 - acc: 0.7575 - val_loss: 0.5894 - val_acc: 0.7628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c-DFcfAiiziz",
        "colab_type": "code",
        "outputId": "22fb356f-feb7-4e6b-8591-d85cc8ef7042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.5890627470970153\n",
            "Test accuracy: 0.7659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xhsyd0rB0kyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we see that changing activation function to sigmoid decreases the accuracy to 76% as compared to the activation function relu and softmax which gave an accuracy of about 87% Hence, we make use of relu and softmax as activation function and change the loss function to cosine proximity to see its effect."
      ]
    },
    {
      "metadata": {
        "id": "xedvOlvChqGu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing loss function to cosine proximity "
      ]
    },
    {
      "metadata": {
        "id": "odE4JHcQuLqi",
        "colab_type": "code",
        "outputId": "1b25bdfd-2c88-424c-fcc9-6d0d406163ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/2\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.8402 - acc: 0.8119 - val_loss: -0.8797 - val_acc: 0.8559\n",
            "Epoch 2/2\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.8956 - acc: 0.8766 - val_loss: -0.8958 - val_acc: 0.8765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K2XtCYjcwgCh",
        "colab_type": "code",
        "outputId": "549c95bd-34ad-4364-9833-db859882d7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.901581658744812\n",
            "Test accuracy: 0.8841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EiBbiSh_2Hkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, changing loss function to cosine proxity leads to the test accuracy of 88% that is slightly greater than the cross entropy loss function which was 87% . Now, let us use both cosine proximity and cross entropy as our loss function and change the number of epochs to see its effect on the accuracy."
      ]
    },
    {
      "metadata": {
        "id": "-t23_6C_hcjb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing number of Epochs to 5"
      ]
    },
    {
      "metadata": {
        "id": "AdmVN5IcTpcX",
        "colab_type": "code",
        "outputId": "45f2ea68-040f-4cf8-b0e5-d180dda4ce97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.8339 - acc: 0.8030 - val_loss: -0.8783 - val_acc: 0.8560\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.8939 - acc: 0.8740 - val_loss: -0.8979 - val_acc: 0.8777\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.9082 - acc: 0.8918 - val_loss: -0.9047 - val_acc: 0.8878\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9173 - acc: 0.9027 - val_loss: -0.9162 - val_acc: 0.9007\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9245 - acc: 0.9110 - val_loss: -0.9174 - val_acc: 0.9031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fp4f4-UhgzJU",
        "colab_type": "code",
        "outputId": "8f479a5b-fc30-4cab-815d-3a3efdb6d663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.9201883563041687\n",
            "Test accuracy: 0.9064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qkHHrVj8xfrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For loss function - cosine proximity, we see that test accuracy increased to 90% with loss of about -0.92. Now, let us the its effect on loss function - Cross Entropy"
      ]
    },
    {
      "metadata": {
        "id": "syqwzvhsxYTr",
        "colab_type": "code",
        "outputId": "6779e161-eceb-4af7-d71f-f8034dd63ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: 0.5272 - acc: 0.8101 - val_loss: 0.3718 - val_acc: 0.8683\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: 0.3357 - acc: 0.8788 - val_loss: 0.3408 - val_acc: 0.8760\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: 0.2889 - acc: 0.8956 - val_loss: 0.2848 - val_acc: 0.8963\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.2556 - acc: 0.9062 - val_loss: 0.2713 - val_acc: 0.9020\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: 0.2275 - acc: 0.9167 - val_loss: 0.2665 - val_acc: 0.9038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ElWZPZkjyGw9",
        "colab_type": "code",
        "outputId": "44852b0d-1bc8-476a-da6d-9ac3f65f2833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.25092555755376816\n",
            "Test accuracy: 0.9076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NZN2lwX03-ZS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we see that the accuracy does not increase much while the test loss increases to 0.25. Hence, we continue with loss function - cosine proximity. Now, let us increase the number of epochs and see if it has any effect."
      ]
    },
    {
      "metadata": {
        "id": "bi1y3wbQqq8V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing number of Epochs to 7"
      ]
    },
    {
      "metadata": {
        "id": "n0mZhwsPqkvP",
        "colab_type": "code",
        "outputId": "53041377-7538-4291-d5fc-71db4448f73b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 7\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/7\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.8378 - acc: 0.8076 - val_loss: -0.8831 - val_acc: 0.8618\n",
            "Epoch 2/7\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.8922 - acc: 0.8720 - val_loss: -0.9000 - val_acc: 0.8806\n",
            "Epoch 3/7\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9066 - acc: 0.8902 - val_loss: -0.9067 - val_acc: 0.8903\n",
            "Epoch 4/7\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9173 - acc: 0.9023 - val_loss: -0.9130 - val_acc: 0.8961\n",
            "Epoch 5/7\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.9243 - acc: 0.9115 - val_loss: -0.9164 - val_acc: 0.9024\n",
            "Epoch 6/7\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9304 - acc: 0.9189 - val_loss: -0.9120 - val_acc: 0.8937\n",
            "Epoch 7/7\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9363 - acc: 0.9261 - val_loss: -0.9180 - val_acc: 0.9023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vktymlj5qubm",
        "colab_type": "code",
        "outputId": "ba9c318d-05c3-44c5-e9a9-5ea97366e3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.9222356794357299\n",
            "Test accuracy: 0.9074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vZD5WCGI4po5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Increasing the epochs to 7, increases the test accuracy to 0.9074 which was earlier 0.9064 for 5 epochs. The increase in the accuracy is not much and we see that it plateaus, so it is better to use 5 epochs and not 7 as it impacts the performance.\n",
        "\n",
        "Let us now change the gradient estimator to stochastic gradient descent and see its impact."
      ]
    },
    {
      "metadata": {
        "id": "JZBUo5OwsjxF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing Gradient estimation to Stochastic Gradient Descent"
      ]
    },
    {
      "metadata": {
        "id": "f1QXV5twsaJh",
        "colab_type": "code",
        "outputId": "902e9f15-0d66-430e-c6ae-3919fefe70c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: -0.6117 - acc: 0.6021 - val_loss: -0.7350 - val_acc: 0.6910\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: -0.7613 - acc: 0.7226 - val_loss: -0.7681 - val_acc: 0.7209\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.7855 - acc: 0.7485 - val_loss: -0.7975 - val_acc: 0.7722\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: -0.8012 - acc: 0.7667 - val_loss: -0.8068 - val_acc: 0.7755\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: -0.8131 - acc: 0.7811 - val_loss: -0.8168 - val_acc: 0.7973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v2RisZ4Es8yy",
        "colab_type": "code",
        "outputId": "9d282e76-e896-4b09-a291-eb030ef08080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.48522751784324647\n",
            "Test accuracy: 0.8225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NXwFE-om_FQH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we see that the test accuracy dropped to 82% and loss increased to 0.48. Hence, it is better to use Adam optimizer than stochastic gradient descent. Let us change it to Adamax and see its impact."
      ]
    },
    {
      "metadata": {
        "id": "qfDG95fetOEt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing Gradient estimation to Adamax"
      ]
    },
    {
      "metadata": {
        "id": "Rxcnz4EYtdbg",
        "colab_type": "code",
        "outputId": "abfdc2d2-fe3a-4d7c-dd99-a1bf157c3b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='Adamax',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.8271 - acc: 0.7964 - val_loss: -0.8762 - val_acc: 0.8545\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.8869 - acc: 0.8664 - val_loss: -0.8927 - val_acc: 0.8739\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9009 - acc: 0.8835 - val_loss: -0.8975 - val_acc: 0.8788\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9091 - acc: 0.8926 - val_loss: -0.9064 - val_acc: 0.8882\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9181 - acc: 0.9041 - val_loss: -0.9124 - val_acc: 0.8960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bUnCq-sIt9b1",
        "colab_type": "code",
        "outputId": "3a62d096-57d8-4031-ce52-a89623ee626f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.9144185781478882\n",
            "Test accuracy: 0.8985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "01aMXQYJAfhU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we see that the test accuracy increased to 89% and loss decreased back to -0.91. But, adam optimizer gave accuracy of 90% with loss of -0.92. Hence, Adam optimizer gives better accuracy so it is better to use it to configure the learning process.\n",
        "\n",
        "Let us now try to change the number of layers in the network architecture and see its impact."
      ]
    },
    {
      "metadata": {
        "id": "xgIFjUwhuX0W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing Network architecture - Number of layers to 2"
      ]
    },
    {
      "metadata": {
        "id": "XIU8Z1nmwRr3",
        "colab_type": "code",
        "outputId": "4a700c7c-b488-4775-ac16-19623087f3f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "# Add convolution 2D\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "#                  activation='relu',\n",
        "#                  kernel_initializer='he_normal',\n",
        "#                  input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 128s 3ms/sample - loss: -0.8347 - acc: 0.8125 - val_loss: -0.8958 - val_acc: 0.8767\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 127s 3ms/sample - loss: -0.9084 - acc: 0.8921 - val_loss: -0.9158 - val_acc: 0.9003\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 128s 3ms/sample - loss: -0.9227 - acc: 0.9091 - val_loss: -0.9215 - val_acc: 0.9069\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 127s 3ms/sample - loss: -0.9330 - acc: 0.9217 - val_loss: -0.9222 - val_acc: 0.9077\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 126s 3ms/sample - loss: -0.9406 - acc: 0.9307 - val_loss: -0.9275 - val_acc: 0.9135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k7Z_uQNSz8KK",
        "colab_type": "code",
        "outputId": "02de40c5-c5de-461f-cfa7-986bee6104e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.9315527265548706\n",
            "Test accuracy: 0.9176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S0AmBsX4B_CD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we can see that decreasing the layer to 2 in the network architecture gave an accuracy of 91% which increased compared to that of 3 layer architecture with accuracy of 90%. Decreasing the layer in architecture also improves the performance and hence we will consider a 2-layer architecture.\n",
        "\n",
        "Let us try to reduce the layer to 1 and see its impact."
      ]
    },
    {
      "metadata": {
        "id": "rETuwi_LCAWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing Network architecture - Number of layers to 1"
      ]
    },
    {
      "metadata": {
        "id": "-OPCd-ijCGrv",
        "colab_type": "code",
        "outputId": "ac4ef6a2-9ba4-417a-f8d2-6cf2c3b5455e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "#Add convolution 2D\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "#                  activation='relu',\n",
        "#                  kernel_initializer='he_normal',\n",
        "#                  input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Conv2D(64, \n",
        "#                  kernel_size=(3, 3), \n",
        "#                  activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 184s 4ms/sample - loss: -0.8351 - acc: 0.8148 - val_loss: -0.9030 - val_acc: 0.8852\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 183s 4ms/sample - loss: -0.9150 - acc: 0.8998 - val_loss: -0.9136 - val_acc: 0.8982\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 182s 4ms/sample - loss: -0.9293 - acc: 0.9182 - val_loss: -0.9136 - val_acc: 0.8963\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 182s 4ms/sample - loss: -0.9414 - acc: 0.9325 - val_loss: -0.9171 - val_acc: 0.9005\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 182s 4ms/sample - loss: -0.9496 - acc: 0.9430 - val_loss: -0.9187 - val_acc: 0.9033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uSxDw1o7Elks",
        "colab_type": "code",
        "outputId": "bd27c949-2df3-4c4e-a992-ebdee6426067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.9220789421081543\n",
            "Test accuracy: 0.9078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gtam09lxMm2D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that the accuracy decreases back to 90% with test loss of -0.92. Hence, we keep a 2 layer architecture for our problem which gives best accuracy."
      ]
    },
    {
      "metadata": {
        "id": "uJVy8wdFNPkw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing Network initializer to uniform"
      ]
    },
    {
      "metadata": {
        "id": "bIgCtXvfLgD8",
        "colab_type": "code",
        "outputId": "1de71c68-1d9d-4e54-a60c-90a4d784c933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "#Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='uniform',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.7922 - acc: 0.7562 - val_loss: -0.8614 - val_acc: 0.8322\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.8729 - acc: 0.8492 - val_loss: -0.8839 - val_acc: 0.8611\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.8914 - acc: 0.8709 - val_loss: -0.8969 - val_acc: 0.8772\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9029 - acc: 0.8851 - val_loss: -0.9051 - val_acc: 0.8872\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9101 - acc: 0.8935 - val_loss: -0.9097 - val_acc: 0.8920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wL2d2oHcNOb7",
        "colab_type": "code",
        "outputId": "002e0273-2234-4779-c761-d67a89026467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.9103037516593933\n",
            "Test accuracy: 0.8936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TYhiswhKP6OM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While changing the kernel initializer to uniform, we see that the accuracy is less - 89% and hence let us change it to random uniform and see if it has a positive impact on the accuracy."
      ]
    },
    {
      "metadata": {
        "id": "VWVuhymsPCJH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Changing Network initializer to random uniform"
      ]
    },
    {
      "metadata": {
        "id": "GzxLm-s5O8EF",
        "colab_type": "code",
        "outputId": "891549d3-1e42-45f7-d5e0-7df679350f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "NO_EPOCHS = 5\n",
        "model = Sequential()\n",
        "#Add convolution 2D\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='random_uniform',\n",
        "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, \n",
        "                 kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.cosine_proximity,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/5\n",
            "48000/48000 [==============================] - 56s 1ms/sample - loss: -0.7935 - acc: 0.7555 - val_loss: -0.8533 - val_acc: 0.8238\n",
            "Epoch 2/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.8767 - acc: 0.8538 - val_loss: -0.8901 - val_acc: 0.8682\n",
            "Epoch 3/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.8951 - acc: 0.8744 - val_loss: -0.9004 - val_acc: 0.8816\n",
            "Epoch 4/5\n",
            "48000/48000 [==============================] - 55s 1ms/sample - loss: -0.9060 - acc: 0.8884 - val_loss: -0.8955 - val_acc: 0.8732\n",
            "Epoch 5/5\n",
            "48000/48000 [==============================] - 54s 1ms/sample - loss: -0.9130 - acc: 0.8965 - val_loss: -0.9112 - val_acc: 0.8943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OEhGYCG8PHaq",
        "colab_type": "code",
        "outputId": "14ddf529-243a-4afb-be14-ed79b48937c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: -0.9117093379020691\n",
            "Test accuracy: 0.8959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ko0viYpRQVXP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here the accuracy is less which is 89% and so we keep the kernel initializer as he_uniform only for our modelling to get best accuracy of 90% and test loss of -0.92"
      ]
    },
    {
      "metadata": {
        "id": "LKYJNXzyUTOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CONCLUSION"
      ]
    },
    {
      "metadata": {
        "id": "Se6nHnZqUWzN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Acheived best accuracy of 90% and test loss of -0.92 using CNN to classify the Fashion MNIST images by tuning various hyper-parameters and trying out different activation function, cost functions and even by changing network architecture."
      ]
    },
    {
      "metadata": {
        "id": "JAqkw0ZlUWv1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CONTRIBUTION"
      ]
    },
    {
      "metadata": {
        "id": "0n5H7I5cUWst",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Personal contribution: 80% External references: 20%"
      ]
    },
    {
      "metadata": {
        "id": "2kpsk8dRUWpt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CITATIONS/REFERENCES"
      ]
    },
    {
      "metadata": {
        "id": "IgUbvyh9UWeO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. https://keras.io/getting-started/sequential-model-guide/\n",
        "2. https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
        "3. https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n",
        "4. https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/\n",
        "5. https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
        "6. https://isaacchanghau.github.io/post/loss_functions/\n",
        "7. https://ieeexplore.ieee.org/document/8285338\n",
        "8. https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f"
      ]
    },
    {
      "metadata": {
        "id": "l_KnoxITUp8q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LICENSE"
      ]
    },
    {
      "metadata": {
        "id": "zVi2FeCTUp5Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2019, Ami Gandhi\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    }
  ]
}